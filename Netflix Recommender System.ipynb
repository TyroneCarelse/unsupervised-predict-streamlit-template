{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.stonesincuba.com/wp-content/uploads/2020/06/Best-Movies-On-Netflix.jpg\" style=\"width:500px;height:600px:\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective-of-this-notebook\" data-toc-modified-id=\"Objective-of-this-notebook-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Objective of this notebook</a></span></li><li><span><a href=\"#Problem-we-seek-to-address\" data-toc-modified-id=\"Problem-we-seek-to-address-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Problem we seek to address</a></span></li><li><span><a href=\"#Datasources-we-seek-to-base-our-models-on\" data-toc-modified-id=\"Datasources-we-seek-to-base-our-models-on-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Datasources we seek to base our models on</a></span></li></ul></li><li><span><a href=\"#Importing-the-necessary-packages\" data-toc-modified-id=\"Importing-the-necessary-packages-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importing the necessary packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installing-the-necessary-packages\" data-toc-modified-id=\"Installing-the-necessary-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Installing the necessary packages</a></span></li><li><span><a href=\"#Importing-all-the-data-wrangling-packages\" data-toc-modified-id=\"Importing-all-the-data-wrangling-packages-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Importing all the data-wrangling packages</a></span></li><li><span><a href=\"#Importing-all-the-visualization-pacakges\" data-toc-modified-id=\"Importing-all-the-visualization-pacakges-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Importing all the visualization pacakges</a></span></li><li><span><a href=\"#Importing-all-the-model-building-packages\" data-toc-modified-id=\"Importing-all-the-model-building-packages-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Importing all the model building packages</a></span></li></ul></li><li><span><a href=\"#Exploring-the-Data\" data-toc-modified-id=\"Exploring-the-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploring the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Displaying-the-heads-of-the-tables\" data-toc-modified-id=\"Displaying-the-heads-of-the-tables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Displaying the heads of the tables</a></span></li><li><span><a href=\"#Checking-for-null-values,-shapes-and-datatypes\" data-toc-modified-id=\"Checking-for-null-values,-shapes-and-datatypes-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Checking for null-values, shapes and datatypes</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Splitting-the-data\" data-toc-modified-id=\"Splitting-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Splitting the data</a></span></li><li><span><a href=\"#Text-Pre-processing\" data-toc-modified-id=\"Text-Pre-processing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Text Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standardizing-the-train-set\" data-toc-modified-id=\"Standardizing-the-train-set-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Standardizing the train set</a></span></li></ul></li><li><span><a href=\"#Model-Building,-training-and-assessment\" data-toc-modified-id=\"Model-Building,-training-and-assessment-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model Building, training and assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-1:-Building-and-training\" data-toc-modified-id=\"Model-1:-Building-and-training-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Model 1: Building and training</a></span></li><li><span><a href=\"#Model-1:-Assessing-the-model\" data-toc-modified-id=\"Model-1:-Assessing-the-model-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Model 1: Assessing the model</a></span></li><li><span><a href=\"#Model-2:-Building-and-training\" data-toc-modified-id=\"Model-2:-Building-and-training-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Model 2: Building and training</a></span></li><li><span><a href=\"#Model-2:-Assessing-the-model\" data-toc-modified-id=\"Model-2:-Assessing-the-model-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Model 2: Assessing the model</a></span></li></ul></li><li><span><a href=\"#Model-Deployment\" data-toc-modified-id=\"Model-Deployment-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Model Deployment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exporting-the-best-model-to-the-Kaggle-leaderboard\" data-toc-modified-id=\"Exporting-the-best-model-to-the-Kaggle-leaderboard-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Exporting the best model to the Kaggle leaderboard</a></span></li><li><span><a href=\"#Exporting-our-finding-via-a-streamlit-app\" data-toc-modified-id=\"Exporting-our-finding-via-a-streamlit-app-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Exporting our finding via a streamlit app</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective with this notebook is to build a movie recommender algorithm that can accurately predict how a user will rate a movie based on their historical preferences. The algorithm should either make use of collaborative filtering or content based filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This forms part of a public Kaggle competition and will be evaluated by the best RMSE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also build a streamlit app hosted in AWS EC2 to communicate our findings to a board of executive stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem we seek to address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewers of movies want to watch movies that they will like. This will increase their satisfaction and will make them more loyal to the Netflix platform which will extend the duration of their subscription, and cause them to recommend this platform to others over against the platforms of their competition (like Showmax). This will result in more loyal customers which will result in greater income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasources we seek to base our models on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MovieLens has gathered millions of movie ratings together with the movieId, UserId, and timestamp when the movie was rated. We also have the following information available on each movie from other public sources: 1. Movie-titles, 2. Movie-genres, 3. Title-cast, 4. Movie-budget, 5. Plot-keywords, 6. Director, 7. Runtime, 8. genome-scores.\n",
    "\n",
    "We will seek to use all of the data above to train our unsupervised machine learning models on to build the best recommender system within our abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we jump in, it is necessary to install and import some python packages that will help us in our quest. We are indebted to those who have contributed to building these packages and making them freely available. Note there might be some packages that you first need to install on your local machine before it will run. Some of the common ones we have commented below and you can just remove the hashtag to install them on your local machine and then comment it out again after it has been installed on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the data-wrangling packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the visualization pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the model building packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/sample_submission.csv')\n",
    "df_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/movies.csv')\n",
    "df_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_tags.csv')\n",
    "df_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/test.csv')\n",
    "df_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/tags.csv')\n",
    "df_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can build our models it is important to just get a basic understanding of the data we are working with so that we can make use of feature engineering, pre-process the data accurately and choose the right models. In this section we will display and draw insights from the data we are working with by using both visual and non-visual display methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Descriptions**\n",
    "\n",
    "The supplied dataset comprises the following:\n",
    "\n",
    "1. **genome_scores.csv** - A score mapping the strength between movies and tag-related properties\n",
    "2. **train.csv** - The training split of the dataset. Contains user and movie IDs with associated rating data\n",
    "3. **test.csv** - The test split of the dataset. Contains user and movie IDs with no rating data\n",
    "4. **tags.csv** - User assigned for the movies within the dataset\n",
    "5. **links.csv** - File providing a mapping between a movie ID, IMDB IDs and TMDB IDs\n",
    "6. **movies** - File providing details about the title of the movie, genres and movieID that further can be used to merge to other related dataset\n",
    "7. **imdb_data.csv** - Additional movie metadata scraped from IMDB using the links.csv file\n",
    "8. **genome_tags.csv** - User assigned tags for genome-related scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list that contains the names of all the dataframes \n",
    "dfs = [df_train, df_test, df_genome_scores, df_genome_tags, df_imdb, df_links, df_movies, df_tags]\n",
    "\n",
    "# Create a list of the names of the imported datasets\n",
    "df_names = ['train', 'test', 'genome_scores', 'genome_tags',\n",
    "            'imdb_data', 'links', 'movies', 'tags']\n",
    "\n",
    "# Creating an empty dictionary\n",
    "dfs_dict = {}  \n",
    "\n",
    "# Iterating over the list and dictionary\n",
    "for name, data in zip(df_names, dfs):  \n",
    "    dfs_dict[name] = [data.shape[0], data.shape[1]]\n",
    "    df_prop = pd.DataFrame(dfs_dict,\n",
    "                          index=['rows', 'columns']).transpose()\n",
    "df_entries_count = df_prop.sort_values(by='rows', ascending=False)\n",
    "\n",
    "# Viewing the final output\n",
    "df_entries_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe above displayed above has all the various dataframes in our entire data set. This is vital information as it shows us how many entries are in each datframe and the columns they each have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the heads of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the train data to see the data present in the table\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test dataframe only has two columns, which is two columns less than the train dataframe. The data we use to test the models later on in the notebook should have the same numnber of columns as the train dataframe, whatever changes we apply to the train data should be applied to the testing data prior to modelling. In a later stage two more columns will be added to the test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null-values, shapes and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the inforation of the train data, the object types, the totak number of columns etc\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our train data set has 10000038 entries, 4 columns, 1 float type data and 3 integer type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test datframe has 5000019 entries, two columns which are interger type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are zero null values in the test dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index,\n",
    "              palette='Reds_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five most common movie genres are Drama, Comedy, Thriller, Romance and Action. This sugguests that the most watched movies in this data frame belong to these top five genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging various dataframes to create a more comprehensive dataframe for out exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both train and movies datasets by using movieId\n",
    "# as the matching column between both datasets\n",
    "train_movies_df = pd.merge(df_train,\n",
    "                           df_movies,\n",
    "                           how='left',\n",
    "                           on='movieId')\n",
    "\n",
    "# Combining all the observations in movies_metadata_df with imdb_data\n",
    "# using movieId as the matching column between both dataframes\n",
    "movies_imdb_df = pd.merge(train_movies_df,\n",
    "                              df_imdb,\n",
    "                              how='left',\n",
    "                              on='movieId')\n",
    "\n",
    "movies_imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average movie score rating in our data\n",
    "avg_rating = np.mean(movies_imdb_df[\"rating\"])\n",
    "\n",
    "print(f'Average rating score in the movies rating distribution is : {avg_rating} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the ratings distrubution of the movies in our dataset\n",
    "with sns.axes_style('darkgrid'):\n",
    "    g = sns.factorplot(\"rating\", data=movies_imdb_df, aspect=2.5, kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ratings fall in the 4.0 bucket,these suggests that most of the movies found in this data set are rated slightly above the average rating by the viewers. Not that many movies have a rating below 2, the viewers most likely enjoy the majority of the movies in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_ratings(series):\n",
    "    \"\"\"\n",
    "    This function generates a bar plot of the 10 most rated movies\n",
    "    of all time\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    data = series.value_counts().head(10)\n",
    "    plt.figure(figsize = (14,9))\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.barplot(x = data, y = data.index ,order = data.index, \n",
    "                palette = 'rocket', orient = 'h',edgecolor = \"black\")\n",
    "    plt.ylabel('Movies', fontsize = 15)\n",
    "    plt.xlabel('Number of ratings',fontsize = 15)\n",
    "    plt.title('10 most rated movies of all time',fontsize = 18)\n",
    "    plt.show()\n",
    "\n",
    "movie_ratings(movies_imdb_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a valid validation set free from data leakage we will split the train set so that 20% of the data is not processed or trained on, but is kept solely for the purpose of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the models to train effectively the data needs to be cleaned up and rightly categorized. The data also needs to be standardized so that the differences in the range of numerical metrics do not distort the weights the metrics should contribute to the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building, training and assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Assessing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Assessing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the best model to the Kaggle leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting our finding via a streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.792px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
