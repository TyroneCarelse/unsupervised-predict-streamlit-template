{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.stonesincuba.com/wp-content/uploads/2020/06/Best-Movies-On-Netflix.jpg\" style=\"width:500px;height:600px:\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective-of-this-notebook\" data-toc-modified-id=\"Objective-of-this-notebook-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Objective of this notebook</a></span></li><li><span><a href=\"#Problem-we-seek-to-address\" data-toc-modified-id=\"Problem-we-seek-to-address-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Problem we seek to address</a></span></li><li><span><a href=\"#Datasources-we-seek-to-base-our-models-on\" data-toc-modified-id=\"Datasources-we-seek-to-base-our-models-on-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Datasources we seek to base our models on</a></span></li></ul></li><li><span><a href=\"#Importing-the-necessary-packages\" data-toc-modified-id=\"Importing-the-necessary-packages-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importing the necessary packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installing-the-necessary-packages\" data-toc-modified-id=\"Installing-the-necessary-packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Installing the necessary packages</a></span></li><li><span><a href=\"#Importing-all-the-data-wrangling-packages\" data-toc-modified-id=\"Importing-all-the-data-wrangling-packages-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Importing all the data-wrangling packages</a></span></li><li><span><a href=\"#Importing-all-the-visualization-pacakges\" data-toc-modified-id=\"Importing-all-the-visualization-pacakges-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Importing all the visualization pacakges</a></span></li><li><span><a href=\"#Importing-all-the-model-building-packages\" data-toc-modified-id=\"Importing-all-the-model-building-packages-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Importing all the model building packages</a></span></li></ul></li><li><span><a href=\"#Exploring-the-Data\" data-toc-modified-id=\"Exploring-the-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploring the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-Descriptions\" data-toc-modified-id=\"Dataset-Descriptions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><strong>Dataset Descriptions</strong></a></span></li><li><span><a href=\"#Overview-of-the-entire-Dataset\" data-toc-modified-id=\"Overview-of-the-entire-Dataset-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Overview of the entire Dataset</a></span></li><li><span><a href=\"#Displaying-the-heads-of-the-tables\" data-toc-modified-id=\"Displaying-the-heads-of-the-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Displaying the heads of the tables</a></span></li><li><span><a href=\"#Checking-for-null-values,-shapes-and-datatypes\" data-toc-modified-id=\"Checking-for-null-values,-shapes-and-datatypes-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Checking for null-values, shapes and datatypes</a></span></li><li><span><a href=\"#Most-common-Genres\" data-toc-modified-id=\"Most-common-Genres-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Most common Genres</a></span></li><li><span><a href=\"#Ratings-Distribution\" data-toc-modified-id=\"Ratings-Distribution-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Ratings Distribution</a></span></li><li><span><a href=\"#Top-Rated-Movies\" data-toc-modified-id=\"Top-Rated-Movies-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Top Rated Movies</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Splitting-the-data\" data-toc-modified-id=\"Splitting-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Splitting the data</a></span></li><li><span><a href=\"#Text-Pre-processing\" data-toc-modified-id=\"Text-Pre-processing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Text Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standardizing-the-train-set\" data-toc-modified-id=\"Standardizing-the-train-set-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Standardizing the train set</a></span></li></ul></li><li><span><a href=\"#Model-Building,-training-and-assessment\" data-toc-modified-id=\"Model-Building,-training-and-assessment-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model Building, training and assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-1:-Building-and-training\" data-toc-modified-id=\"Model-1:-Building-and-training-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Model 1: Building and training</a></span></li><li><span><a href=\"#Model-1:-Assessing-the-model\" data-toc-modified-id=\"Model-1:-Assessing-the-model-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Model 1: Assessing the model</a></span></li><li><span><a href=\"#Model-2:-Building-and-training\" data-toc-modified-id=\"Model-2:-Building-and-training-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Model 2: Building and training</a></span></li><li><span><a href=\"#Model-2:-Assessing-the-model\" data-toc-modified-id=\"Model-2:-Assessing-the-model-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Model 2: Assessing the model</a></span></li></ul></li><li><span><a href=\"#Exporting-predictions-to-Kaggle\" data-toc-modified-id=\"Exporting-predictions-to-Kaggle-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Exporting predictions to Kaggle</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective with this notebook is to build a movie recommender algorithm that can accurately predict how a user will rate a movie based on their historical preferences. The algorithm should either make use of collaborative filtering or content based filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This forms part of a public Kaggle competition and will be evaluated by the best RMSE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also build a streamlit app hosted in AWS EC2 to communicate our findings to a board of executive stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem we seek to address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewers of movies want to watch movies that they will like. This will increase their satisfaction and will make them more loyal to the Netflix platform which will extend the duration of their subscription, and cause them to recommend this platform to others over against the platforms of their competition (like Showmax). This will result in more loyal customers which will result in greater income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasources we seek to base our models on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MovieLens has gathered millions of movie ratings together with the movieId, UserId, and timestamp when the movie was rated. We also have the following information available on each movie from other public sources: 1. Movie-titles, 2. Movie-genres, 3. Title-cast, 4. Movie-budget, 5. Plot-keywords, 6. Director, 7. Runtime, 8. genome-scores.\n",
    "\n",
    "We will seek to use all of the data above to train our unsupervised machine learning models on to build the best recommender system within our abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we jump in, it is necessary to install and import some python packages that will help us in our quest. We are indebted to those who have contributed to building these packages and making them freely available. Note there might be some packages that you first need to install on your local machine before it will run. Some of the common ones we have commented below and you can just remove the hashtag to install them on your local machine and then comment it out again after it has been installed on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the section below to install packages that might not have been \n",
    "#preinstalled on your local machine.\n",
    "#!conda install -c conda-forge/label/cf202003 scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the data-wrangling packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the visualization pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the model building packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GitHub/genome_scores.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4a82694be0ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movies.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_imdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imdb_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_genome_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GitHub/genome_scores.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf_genome_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'genome_tags.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Atom\\Anacondas\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Atom\\Anacondas\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Atom\\Anacondas\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Atom\\Anacondas\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Atom\\Anacondas\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GitHub/genome_scores.csv'"
     ]
    }
   ],
   "source": [
    "df_sample_submission = pd.read_csv('sample_submission.csv')\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_imdb = pd.read_csv('imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv('genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv('genome_tags.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n",
    "df_links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can build our models it is important to just get a basic understanding of the data we are working with so that we can make use of feature engineering, pre-process the data accurately and choose the right models. In this section we will display and draw insights from the data we are working with by using both visual and non-visual display methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Descriptions**\n",
    "\n",
    "The supplied dataset comprises the following:\n",
    "\n",
    "1. **genome_scores.csv** - A score mapping the strength between movies and tag-related properties\n",
    "2. **train.csv** - The training split of the dataset. Contains user and movie IDs with associated rating data\n",
    "3. **test.csv** - The test split of the dataset. Contains user and movie IDs with no rating data\n",
    "4. **tags.csv** - User assigned for the movies within the dataset\n",
    "5. **links.csv** - File providing a mapping between a movie ID, IMDB IDs and TMDB IDs\n",
    "6. **movies** - File providing details about the title of the movie, genres and movieID that further can be used to merge to other related dataset\n",
    "7. **imdb_data.csv** - Additional movie metadata scraped from IMDB using the links.csv file\n",
    "8. **genome_tags.csv** - User assigned tags for genome-related scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list that contains the names of all the dataframes \n",
    "dfs = [df_train, df_test, df_genome_scores, df_genome_tags, df_imdb, df_links, df_movies, df_tags]\n",
    "\n",
    "# Create a list of the names of the imported datasets\n",
    "df_names = ['train', 'test', 'genome_scores', 'genome_tags',\n",
    "            'imdb_data', 'links', 'movies', 'tags']\n",
    "\n",
    "# Creating an empty dictionary\n",
    "dfs_dict = {}  \n",
    "\n",
    "# Iterating over the list and dictionary\n",
    "for name, data in zip(df_names, dfs):  \n",
    "    dfs_dict[name] = [data.shape[0], data.shape[1]]\n",
    "    df_prop = pd.DataFrame(dfs_dict,\n",
    "                          index=['rows', 'columns']).transpose()\n",
    "df_entries_count = df_prop.sort_values(by='rows', ascending=False)\n",
    "\n",
    "# Viewing the final output\n",
    "df_entries_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe above displayed above has all the various dataframes in our entire data set. This is vital information as it shows us how many entries are in each datframe and the columns they each have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the heads of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the train data to see the data present in the table\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test dataframe only has two columns, which is two columns less than the train dataframe. The data we use to test the models later on in the notebook should have the same numnber of columns as the train dataframe, whatever changes we apply to the train data should be applied to the testing data prior to modelling. In a later stage two more columns will be added to the test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null-values, shapes and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the inforation of the train data, the object types, the totak number of columns etc\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our train data set has 10000038 entries, 4 columns, 1 float type data and 3 integer type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test datframe has 5000019 entries, two columns which are interger type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are zero null values in the test dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index,\n",
    "              palette='Reds_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five most common movie genres are Drama, Comedy, Thriller, Romance and Action. This sugguests that the most watched movies in this data frame belong to these top five genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging various dataframes to create a more comprehensive dataframe for out exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining both train and movies datasets by using movieId\n",
    "# as the matching column between both datasets\n",
    "train_movies_df = pd.merge(df_train,\n",
    "                           df_movies,\n",
    "                           how='left',\n",
    "                           on='movieId')\n",
    "\n",
    "# Combining all the observations in movies_metadata_df with imdb_data\n",
    "# using movieId as the matching column between both dataframes\n",
    "movies_imdb_df = pd.merge(train_movies_df,\n",
    "                              df_imdb,\n",
    "                              how='left',\n",
    "                              on='movieId')\n",
    "\n",
    "movies_imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average movie score rating in our data\n",
    "avg_rating = np.mean(movies_imdb_df[\"rating\"])\n",
    "\n",
    "print(f'Average rating score in the movies rating distribution is : {avg_rating} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the ratings distrubution of the movies in our dataset\n",
    "with sns.axes_style('darkgrid'):\n",
    "    g = sns.factorplot(\"rating\", data=movies_imdb_df, aspect=2.5, kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ratings fall in the 4.0 bucket,these suggests that most of the movies found in this data set are rated slightly above the average rating by the viewers. Not that many movies have a rating below 2, the viewers most likely enjoy the majority of the movies in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directors with the most ratings in the dataset\n",
    "most_rated_director = pd.DataFrame(movies_imdb_df.groupby('director')['rating'].mean().\n",
    "                             sort_values(ascending=False))\n",
    "most_rated_director['No_of_ratings'] = movies_imdb_df.groupby('director')['rating'].count()\n",
    "most_rated_director.sort_values(by=['No_of_ratings', 'rating'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The director with the most ratings is Quentin Tarantino, this does not come as a suprise as this director has several blockbuster movies that performed quite well in box office. This director has directed movies such as Pulp Fiction and Kill Bill just to name a few. J.R.R Tolkein, Steven King and Jonathan Nolan have an average rating of 4.0, which is a higher average than all the directors in our data set got.\n",
    "\n",
    "Both Tolkein and King have very succesful book franchises that we later adapted into movies that got a mostly positive reception from the public. Their ratings could be coming from people who have read the books and went on to watch the movies and those who just watched the movies alone, this doubles the total number of views the movies recieved. The movies are not watched by movie fans alone but also book readers. They capture a wider audiance.\n",
    "\n",
    "Johanthan Nolan has directed movies such as Batman: The Dark Knight and The Dark Knight Rises which performed well at the box office bringing in revenues that far outweighted the movie budgets and recieved positive ratings from movie critics and fans alike. It seems to be that the movie viewers in our dataframe enjoy watching his movies as he has a proven track record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_ratings(series):\n",
    "    \"\"\"\n",
    "    This function generates a bar plot of the 10 most rated movies\n",
    "    of all time\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    data = series.value_counts().head(10)\n",
    "    plt.figure(figsize = (14,9))\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.barplot(x = data, y = data.index ,order = data.index, \n",
    "                palette = 'rocket', orient = 'h',edgecolor = \"black\")\n",
    "    plt.ylabel('Movies', fontsize = 15)\n",
    "    plt.xlabel('Number of ratings',fontsize = 15)\n",
    "    plt.title('10 most rated movies of all time',fontsize = 18)\n",
    "    plt.show()\n",
    "\n",
    "movie_ratings(movies_imdb_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shawshank Redemption is the most rated movie of all time, one of the contributing factors could be that Morgan Freeman is one of the cast members. The actor has amassed a wealth of respect from movie fans and creaters alike. The book the movie was adopted from was written by Stephen King, a well known writer whose works have been adapted into several movies in Hollywood.Forest Gump and Pulp Fiction follow in 2nd and 3rd place respectively. These two movies also cast all star actors such as Tom Hanks,Samuel L. Jackson and John Travolta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a valid validation set free from data leakage we will split the train set so that 20% of the data is not processed or trained on, but is kept solely for the purpose of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the models to train effectively the data needs to be cleaned up and rightly categorized. The data also needs to be standardized so that the differences in the range of numerical metrics do not distort the weights the metrics should contribute to the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building, training and assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Assessing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Assessing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting predictions to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.787px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
